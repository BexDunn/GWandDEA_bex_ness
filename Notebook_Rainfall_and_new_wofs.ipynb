{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# <font color=green>Tasselled Cap Wetness Epoch Stats Summary Notebook</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Loads surface reflectance data from the data cube, calculates tasselled cap indices, and outputs a netcdf file. Created by Bex Dunn modified by Vanessa Newey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "For sensor in sensors:\n",
    "Load data\n",
    "calculate tcw count\n",
    "calculate mean tcw count\n",
    "calculate percentile tcw count (low and high)\n",
    "calculate\n",
    "plot mean tcw count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#for writing to error files:\n",
    "from __future__ import print_function\n",
    "#get some libraries\n",
    "import datacube\n",
    "import xarray as xr\n",
    "from datacube.storage import masking\n",
    "#from datacube.storage.masking import mask_to_dict #think this is obsolete\n",
    "import json\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import shape\n",
    "import numpy as np #need this for pq fuser\n",
    "\n",
    "#libraries for polygon and polygon mask\n",
    "import fiona\n",
    "import shapely.geometry\n",
    "import rasterio.features\n",
    "import rasterio\n",
    "from datacube.utils import geometry\n",
    "from datacube.helpers import ga_pq_fuser\n",
    "from datacube.storage.masking import mask_invalid_data\n",
    "\n",
    "#for writing to netcdf\n",
    "from datacube.storage.storage import write_dataset_to_netcdf\n",
    "#dealing with system commands\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "#####These not needed for raijin::::\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#suppress warnings thrown when using inequalities in numpy (the threshold values!)\n",
    "import warnings\n",
    "\n",
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_nbart(sensor,query,bands_of_interest): \n",
    "    '''loads nbart data for a sensor, masks using pq, then filters out terrain -999s\n",
    "    function written 23-08-2017 based on dc v1.5.1'''  \n",
    "    dataset = []\n",
    "    product_name = '{}_{}_albers'.format(sensor, 'nbart')\n",
    "    print('loading {}'.format(product_name))\n",
    "    ds = dc.load(product=product_name, measurements=bands_of_interest,\n",
    "                 group_by='solar_day', **query)\n",
    "    #grab crs defs from loaded ds if ds exists\n",
    "    if ds:\n",
    "        crs = ds.crs\n",
    "        affine = ds.affine\n",
    "        print('loaded {}'.format(product_name))\n",
    "        mask_product = '{}_{}_albers'.format(sensor, 'pq')\n",
    "        sensor_pq = dc.load(product=mask_product, fuse_func=ga_pq_fuser,\n",
    "                            group_by='solar_day', **query)\n",
    "        if sensor_pq:\n",
    "            print('making mask {}'.format(mask_product))\n",
    "            cloud_free = masking.make_mask(sensor_pq.pixelquality,\n",
    "                                           cloud_acca='no_cloud',\n",
    "                                           cloud_shadow_acca = 'no_cloud_shadow',                           \n",
    "                                           cloud_shadow_fmask = 'no_cloud_shadow',\n",
    "                                           cloud_fmask='no_cloud',\n",
    "                                           blue_saturated = False,\n",
    "                                           green_saturated = False,\n",
    "                                           red_saturated = False,\n",
    "                                           nir_saturated = False,\n",
    "                                           swir1_saturated = False,\n",
    "                                           swir2_saturated = False,\n",
    "                                           contiguous=True)\n",
    "            ds = ds.where(cloud_free)\n",
    "            ds.attrs['crs'] = crs\n",
    "            ds.attrs['affine'] = affine\n",
    "            print('masked {} with {} and filtered terrain'.format(product_name,mask_product))\n",
    "            # nbarT is correctly used to correct terrain by replacing -999.0 with nan\n",
    "            ds=ds.where(ds!=-999.0)\n",
    "        else: \n",
    "            print('did not mask {} with {}'.format(product_name,mask_product))\n",
    "    else:\n",
    "        print ('did not load {}'.format(product_name)) \n",
    "\n",
    "    if len(ds)>0:\n",
    "        return ds\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_wetness(sensor_data,sensor):\n",
    "    '''This function multiplies band data by wetness coefficients to produce a \"wetness\" band.\n",
    "    sensor_data is surface reflectance data loaded from the datacube\n",
    "    sensor = 'ls5, 'ls7' or 'ls8'\n",
    "    Coefficients are from Crist and Cicone 1984 for ls5 and ls7, and from Baig, Zhang, Shuai & Tong for ls8\n",
    "    function written 23-08-2017 based on dc v1.5.1'''\n",
    "    \n",
    "    wetness_coeff ={'ls5':{'blue':0.151, 'green':0.179, 'red':0.330, 'nir':0.341, 'swir1':-0.711, 'swir2':-0.457},\n",
    "                    'ls7':{'blue':0.151, 'green':0.179, 'red':0.330, 'nir':0.341, 'swir1':-0.711, 'swir2':-0.457},\n",
    "                    'ls8':{'blue':0.1511,'green':0.1973,'red':0.3283,'nir':0.3407,'swir1':-0.7117,'swir2':-0.4559}}  \n",
    "    \n",
    "    #if there is sensor data for the time period\n",
    "    if sensor_data is not None: \n",
    "        #make a deep copy of the sensor data\n",
    "        wetness = sensor_data.copy(deep=True)\n",
    "        #iterate over the spectral bands\n",
    "        for band_name in sensor_data.data_vars:\n",
    "            #multiply each band by the wetness transform coefficient to get a band-specific wetness value\n",
    "            wetness_band = sensor_data[band_name]*wetness_coeff[sensor][band_name]\n",
    "            #update the existing band data with the wetness data\n",
    "            wetness.update({band_name:(['time','y','x'],wetness_band)})\n",
    "        #finally, add a wetness data variable to the array that is the sum of the wetness \"bands\"    \n",
    "        wetness['wetness']=wetness.blue+wetness.green+wetness.red+wetness.nir+wetness.swir1+wetness.swir2    \n",
    "        print('calculated wetness for {}'.format(sensor))\n",
    "        wetness = wetness.drop(('blue','green','red','nir','swir1','swir2'))\n",
    "        return wetness\n",
    "    \n",
    "    else:\n",
    "        print('did not calculate wetness for {}'.format(sensor))\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def calc_wetveg_overthresh(wetness,threshold=-400):\n",
    "    '''Calculate the wetness values where wetness>threshold. Inputs are wetness array and threshold value, \n",
    "    default threshold is -400. Band for wetness>threshold is added to wetness. This is not the count.'''\n",
    "    if wetness is not None:\n",
    "        with warnings.catch_warnings():\n",
    "            #suppress irritating behaviour in xarray.where\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            #water_plus_wetveg is wetness values where wetness>threshold\n",
    "            wetness['water_plus_wetveg'] = wetness.wetness.where(wetness.wetness>threshold)\n",
    "            print('thresholded wetness added to array')\n",
    "            return wetness\n",
    "    else:\n",
    "        print('did not calculate wetness overthreshold' )\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def count_wets(wetness):\n",
    "    '''count the number of wetness scenes for each pixel,\n",
    "    count the amount of times that water plus wet veg is above the threshold\n",
    "    load both into memory (this assumes you are using dask),\n",
    "    return a dictionary of wet count and threshold count'''\n",
    "    if wetness is not None:\n",
    "        #count the number of wetness scenes for each pixel\n",
    "        wet_count = wetness.wetness.count(dim='time')\n",
    "\n",
    "        #count the amount of times that water plus wet veg is above the threshold\n",
    "        threshold_count= wetness.water_plus_wetveg.count(dim='time')\n",
    "        \n",
    "        #bring both counts into memory\n",
    "        wet_count.load()\n",
    "        threshold_count.load()\n",
    "        \n",
    "        #define dictionary of wet count and threshold count\n",
    "        counts = {'wet count':wet_count, 'threshold count':threshold_count}\n",
    "        print('counted')\n",
    "        return counts\n",
    "    else:\n",
    "        print('did not count' )\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def count_wets(wetness):\n",
    "    '''count the number of wetness scenes for each pixel,\n",
    "    count the amount of times that water plus wet veg is above the threshold\n",
    "    load both into memory (this assumes you are using dask),\n",
    "    return a dictionary of wet count and threshold count'''\n",
    "    if wetness is not None:\n",
    "        #count the number of wetness scenes for each pixel\n",
    "        wet_count = wetness.wetness.count(dim='time')\n",
    "\n",
    "        #count the amount of times that water plus wet veg is above the threshold\n",
    "        threshold_count= wetness.water_plus_wetveg.count(dim='time')\n",
    "        \n",
    "        #bring both counts into memory\n",
    "        wet_count.load()\n",
    "        threshold_count.load()\n",
    "        \n",
    "        #define dictionary of wet count and threshold count\n",
    "        counts = {'wet count':wet_count, 'threshold count':threshold_count}\n",
    "        print('counted')\n",
    "        return counts\n",
    "    else:\n",
    "        print('did not count' )\n",
    "        return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def write_your_netcdf(data, dataset_name, filename,crs):\n",
    "    '''this function turns an xarray dataarray into a dataset so we can write it to netcdf. It adds on a crs definition\n",
    "    from the original array. data = your xarray dataset, dataset_name is a string describing your variable'''    \n",
    "    #turn array into dataset so we can write the netcdf\n",
    "    dataset= data.to_dataset(name=dataset_name)\n",
    "    #grab our crs attributes to write a spatially-referenced netcdf\n",
    "    dataset.attrs['crs'] = crs\n",
    "    #dataset.dataset_name.attrs['crs'] = crs\n",
    "    try:\n",
    "        write_dataset_to_netcdf(dataset, filename)\n",
    "    except RuntimeError as err:\n",
    "        print(\"RuntimeError: {0}\".format(err))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_wofs(query):\n",
    "    \n",
    "    #Create a query to store spatiotemporal information from the previous landsat query\n",
    "    wofs_query = query\n",
    "    dcwofs = datacube.Datacube(config='/g/data/r78/dc_configs/wofscube.conf')\n",
    "    \n",
    "    wofs_data = dcwofs.load(product = 'wofs_albers', **wofs_query)\n",
    "\n",
    "    #Concatenate (join) the data from the different WOfS scenes together and sort so that observations are sorted \n",
    "    #by time\n",
    "\n",
    "    #xr_wofs = xr.DataArray(wofs_data)\n",
    "    return wofs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_rainfall(query):\n",
    "    \n",
    "    dc_rf =datacube.Datacube(config='/g/data/r78/bom_grids/rainfall.conf')\n",
    "    \n",
    "    rf_data = dc_rf.load(product = 'rainfall_grids_1901_2017',**query)\n",
    "\n",
    "    return rf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Enter input shapefile, output file and start and end date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#save netcdf outputs to this folder:\n",
    "#netcdf_output_loc ='/g/data/r78/rjd547/groundwater_activities/Analysis/'\n",
    "\n",
    "netcdf_output_loc ='/g/data/r78/vmn547/TCW_stats/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e881c58bcf43e087f5553796109af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Text</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Text(value='/g/data/r78/vmn547/GWandDEA_bex_ness/Little_GW_AOI_for_demo/kEEP_ord/KEEP_AOI.shp', description='path to shape file', layout=Layout(width='70%'), placeholder='update this field', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#code to work with a polygon input\n",
    "shape_file = ('/g/data/r78/vmn547/GWandDEA_bex_ness/Little_GW_AOI_for_demo/kEEP_ord/KEEP_AOI.shp')\n",
    "style = {'description_width': 'initial'}\n",
    "shape_file_text = widgets.Text(value=shape_file,placeholder='update this field',\n",
    "    description='path to shape file',\n",
    "    style = {'description_width': 'initial'},                          \n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='70%'))\n",
    "def handle_shape_file(sender):\n",
    "    shape_file=shape_file_text.value\n",
    "    \n",
    "shape_file_text.observe(handle_shape_file)\n",
    "display(shape_file_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484db9556d4b4c48ad0043ec6d714c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Label</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Label(value='Please enter the filename including the path to the output NetCDF file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e49326fe52a4316be0f7e4e5cb4330c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Text</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Text(value='/g/data/r78/vmn547/TCW_stats/NoPizza4.nc', description='path to output file', layout=Layout(width='70%'), placeholder='update this field', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #check if the file has already been written:\n",
    "filename = netcdf_output_loc+'NoPizza4.nc'\n",
    "infoLabel = widgets.Label(value=\"Please enter the filename including the path to the output NetCDF file\",\n",
    "    color='Red')\n",
    "display(infoLabel)\n",
    "\n",
    "output_file_text = widgets.Text(value=filename,placeholder='update this field',\n",
    "    description='path to output file',\n",
    "    style = {'description_width': 'initial'},\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='70%'))\n",
    "def handle_output_file(sender):\n",
    "    filename=output_file_text.value\n",
    "    if os.path.isfile(filename):\n",
    "        infoLabel.value = '{} already exists please change filename'.format(filename)\n",
    "       # display(infoLabel)\n",
    "    else:\n",
    "        infoLabel.value = '{} is the output filename'.format(filename)\n",
    "output_file_text.on_submit(handle_output_file)\n",
    "display(output_file_text)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#tell the datacube which app to use\n",
    "dc = datacube.Datacube(app='dc-nbar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286cfcdcd2fa4f44964c9b6bffa3cbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Text</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Text(value='2011-01-01', description='start date', placeholder='update this field')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c841d661f9ef4e68a76361968d73fb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Text</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Text(value='2011-12-31', description='end date', placeholder='update this field')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### DEFINE SPATIOTEMPORAL RANGE AND BANDS OF INTEREST\n",
    "#Define temporal range\n",
    "\n",
    "#start_of_epoch = '1987-01-01'\n",
    "#end_of_epoch =  '2016-12-31'\n",
    "start_of_epoch = '2011-01-01'\n",
    "end_of_epoch =  '2011-12-31'\n",
    "#TODO Replace with datepicker widget when ipywidgets devs sort this out\n",
    "from_date_picker = widgets.Text(value=start_of_epoch,placeholder='update this field',\n",
    "    description='start date',\n",
    "    disabled=False)\n",
    "def handle_from_date(sender):\n",
    "    start_of_epoch=from_date_picker.value\n",
    "from_date_picker.observe(handle_from_date)\n",
    "display(from_date_picker)\n",
    "\n",
    "#TODO Replace with datepicker widget when ipywidgets devs sort this out\n",
    "to_date_picker = widgets.Text(value = end_of_epoch,placeholder='update this field',\n",
    "    description='end date',\n",
    "    disabled=False)\n",
    "def handle_to_date(sender):\n",
    "    end_of_epoch = to_date_picker.value\n",
    "to_date_picker.observe(handle_to_date)\n",
    "display(to_date_picker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd95871054041e5a52dffb12c844f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>Button</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "Button(description='Load Data and calculate wetness', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ls5_nbart_albers\n",
      "loaded ls5_nbart_albers\n",
      "making mask ls5_pq_albers\n",
      "masked ls5_nbart_albers with ls5_pq_albers and filtered terrain\n",
      "loading ls7_nbart_albers\n",
      "loaded ls7_nbart_albers\n",
      "making mask ls7_pq_albers\n",
      "masked ls7_nbart_albers with ls7_pq_albers and filtered terrain\n",
      "loading ls8_nbart_albers\n",
      "did not load ls8_nbart_albers\n",
      "Calculate wetness for each timeslice\n",
      "calculated wetness for ls5\n",
      "calculated wetness for ls7\n",
      "did not calculate wetness for ls8\n",
      "Calculate wetness over the threshold for each timeslice (remove values under the threshold)\n",
      "thresholded wetness added to array\n",
      "Count number of wetness scenes and number of times tcw above threshold for each pixel\n",
      "counted\n",
      "Divide the number of times wetness is seen per pixel by the number of wetness scenes per pixel to get a proportion of time that the pixel is wet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaa305aae9945e8ad8cf445342af3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=11, description='n', max=23), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.dates as mdates\n",
    "GoButton= widgets.Button(description='Load Data and calculate wetness')\n",
    "def handle_load_calc(b):\n",
    "    \n",
    "    # open all the shapes within the shape file\n",
    "\n",
    "    shapes = fiona.open(shape_file)\n",
    "    #i is the index of the shape file we have chosen\n",
    "    i =0 \n",
    "    #copy attributes from shapefile and define shape_name\n",
    "    geom_crs = geometry.CRS(shapes.crs_wkt)\n",
    "    geo = shapes[i]['geometry']\n",
    "    geom = geometry.Geometry(geo, crs=geom_crs)\n",
    "    geom_bs = shapely.geometry.shape(shapes[i]['geometry'])\n",
    "    shape_name = shape_file.split('/')[-1].split('.')[0]+'_'+str(i)\n",
    "\n",
    "    filename=output_file_text.value\n",
    "    end_of_epoch = to_date_picker.value\n",
    "    start_of_epoch=from_date_picker.value\n",
    "    \n",
    "    #Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "    bands_of_interest = ['blue',\n",
    "                         'green',\n",
    "                         'red',\n",
    "                         'nir',\n",
    "                         'swir1',\n",
    "                         'swir2'\n",
    "                         ]\n",
    "\n",
    "    query = {\n",
    "        'time': (start_of_epoch, end_of_epoch), 'geopolygon': geom\n",
    "    }\n",
    "\n",
    "\n",
    "    #this is done separately instead of in a loop because the datasets can be quite large.\n",
    "    #currently this is a way of memory handling -there is probably a better way of doing it.\n",
    "    sensor1_nbart=load_nbart('ls5',query,bands_of_interest)\n",
    "    sensor2_nbart=load_nbart('ls7',query,bands_of_interest)\n",
    "    sensor3_nbart=load_nbart('ls8',query,bands_of_interest)\n",
    "\n",
    "    print('Calculate wetness for each timeslice')\n",
    "\n",
    "    wetness_sensor1_nbart=calc_wetness(sensor1_nbart,'ls5')\n",
    "    wetness_sensor2_nbart=calc_wetness(sensor2_nbart,'ls7')\n",
    "    wetness_sensor3_nbart=calc_wetness(sensor3_nbart,'ls8')\n",
    "\n",
    "    print('Calculate wetness over the threshold for each timeslice (remove values under the threshold)')\n",
    "     \n",
    "    wetness_data = [x for x in [wetness_sensor1_nbart,wetness_sensor2_nbart,wetness_sensor3_nbart]  if x is not None]\n",
    "  \n",
    "    wetness_multisensor_nbart = xr.concat(wetness_data, dim='time')\n",
    "    wetness_data = None\n",
    "    wetness_sensor1_nbart = None\n",
    "    wetness_sensor2_nbart = None\n",
    "    wetness_sensor3_nbart = None\n",
    "    \n",
    "    wetness_multi =calc_wetveg_overthresh(wetness_multisensor_nbart)\n",
    " \n",
    "    nbart_data_arrays = [x for x in [sensor1_nbart,sensor2_nbart,sensor3_nbart]  if x is not None]\n",
    "    \n",
    "    nbart_multi = xr.concat(nbart_data_arrays, dim ='time')\n",
    "    nbart_data_arrays = None\n",
    "    sensor1_nbart = None\n",
    "    sensor2_nbart = None\n",
    "    sensor3_nbart = None\n",
    "\n",
    "    wofs = load_wofs(query)\n",
    "    \n",
    "    rf = load_rainfall(query)\n",
    "    # Set the percentage of good data that you'd like to display with pernan variable - 0.9 will return rows that have 90%\n",
    "    # of valid values\n",
    "    pernan = 0.8\n",
    "    water_plus_veg_sum = wetness_multi.dropna('time',  thresh = int(pernan*wetness_multi.wetness.isel(time=0).size))\n",
    "    nbart_multi_drop = nbart_multi.where(nbart_multi.time  == water_plus_veg_sum.time)\n",
    "    wofs_drop = wofs.where(wofs.time == water_plus_veg_sum.time)\n",
    "    \n",
    "    rf_average = rf.rainfall.mean(dim =('longitude','latitude'))\n",
    "    rf_mnthy_average = rf_average.resample('1M', dim='time',how='sum')\n",
    "    \n",
    "    print('Count number of wetness scenes and number of times tcw above threshold for each pixel')\n",
    "\n",
    "    counts_multi_nbart = count_wets(wetness_multisensor_nbart)\n",
    "\n",
    "    print('Divide the number of times wetness is seen per pixel by the number of wetness scenes per pixel to get a proportion of time that the pixel is wet')\n",
    "\n",
    "    #times wetness is over threshold by pixel         \n",
    "    threshold_allsensors =counts_multi_nbart['threshold count']\n",
    "    #number of wetness scenes by pixel\n",
    "    wet_count_allsensors = counts_multi_nbart['wet count']    \n",
    "    wet_proportion_allsensors = threshold_allsensors/wet_count_allsensors\n",
    "\n",
    "\n",
    "    \n",
    "    def f(n):\n",
    "        #try:\n",
    "            plt.clf\n",
    "            plt.close('all')\n",
    "            plot_title_size =20\n",
    "            '''fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(figsize=(15,15),nrows=2,ncols=2)\n",
    "            ax1.plot([1,1])\n",
    "            ax2.plot([2,1])\n",
    "            ax3.plot([1,2])'''\n",
    "            \n",
    "            fig = plt.figure(figsize=(15,20))\n",
    "            \n",
    "            ax1 = plt.subplot2grid((2, 3), (0, 0))\n",
    "            ax2 = plt.subplot2grid((2, 3), (0, 1))\n",
    "            ax3 = plt.subplot2grid((2, 3), (1, 0))\n",
    "            ax4 = plt.subplot2grid((2, 3), (0, 2))\n",
    "            ax5 = plt.subplot2grid((2, 3), (1, 2))\n",
    "            date_ = nbart_multi_drop.isel(time=n).time.data\n",
    "            water_plus_veg_sum.wetness.isel(time=n).plot(ax=ax1, cmap='Blues')\n",
    "            ax1.set_title('Tasselled Cap Wetness\\n' + str(date_), fontsize=plot_title_size)\n",
    "            rgb = nbart_multi_drop.isel(time =n).to_array(dim='color').sel(color=['swir1', 'nir', 'green']).transpose('y', 'x', 'color')\n",
    "            \n",
    "            fake_saturation = 4500\n",
    "            clipped_visible = rgb.where(rgb<fake_saturation).fillna(fake_saturation)\n",
    "            max_val = clipped_visible.max(['y', 'x'])\n",
    "            scaled = (clipped_visible / max_val)\n",
    "            \n",
    "            \n",
    "            im = ax2.imshow(scaled, interpolation = 'nearest',\n",
    "               extent=[scaled.coords['x'].min(), scaled.coords['x'].max(), \n",
    "                       scaled.coords['y'].min(), scaled.coords['y'].max()])\n",
    "            \n",
    "            \n",
    "            ax2.set_title('False Colour Composite\\n' + str(date_), fontsize=plot_title_size)\n",
    "\n",
    "            \n",
    "            wet_proportion_allsensors.plot(ax=ax3, cmap ='gist_earth_r')\n",
    "            \n",
    "            fig.text=str(water_plus_veg_sum.wetness.isel(time=n).time)\n",
    "            ax3.set_title('     Percentage of Landsat images ' + start_of_epoch + \\\n",
    "                          ' to ' + end_of_epoch + ' \\nwhere pixel exceeds\\n' + \\\n",
    "                             'Tasselled Cap wetness index threshold (-400)',fontsize=plot_title_size)\n",
    "            \n",
    "            wofs_cmap = mpl.colors.ListedColormap(['#ffffff','#0000ff','#000000'])\n",
    "            wofs_drop.water.isel(time=n).plot(ax=ax4,levels=[0,128,129,500], cmap=wofs_cmap)\n",
    "            ax4.set_title('Wofs\\n' + str(date_), fontsize=plot_title_size)\n",
    "            \n",
    "            \n",
    "            ax5.plot(rf_mnthy_average.time,rf_mnthy_average.values)\n",
    "           \n",
    "            \n",
    "            ax5.set_title('Rainfall\\n')\n",
    "            #plt.tight_layout()\n",
    "            plt.show()\n",
    "        #except:\n",
    "            print('timeslice ' + str(water_plus_veg_sum.wetness.isel(time=n).time.time) + ' has some null data')\n",
    "\n",
    "\n",
    "    timeslices = len(water_plus_veg_sum.time)                                    \n",
    "    \n",
    "    interact(f,n=(0,timeslices-1),value=timeslices-1,width = '350px')\n",
    "   \n",
    "    display()\n",
    "\n",
    "   \n",
    "display(GoButton)\n",
    "GoButton.on_click(handle_load_calc)\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    " # open all the shapes within the shape file\n",
    "if False:\n",
    "    shapes = fiona.open(shape_file)\n",
    "    #i is the index of the shape file we have chosen\n",
    "    i =0 \n",
    "    #copy attributes from shapefile and define shape_name\n",
    "    geom_crs = geometry.CRS(shapes.crs_wkt)\n",
    "    geo = shapes[i]['geometry']\n",
    "    geom = geometry.Geometry(geo, crs=geom_crs)\n",
    "    geom_bs = shapely.geometry.shape(shapes[i]['geometry'])\n",
    "    shape_name = shape_file.split('/')[-1].split('.')[0]+'_'+str(i)\n",
    "    print(geo)\n",
    "    print(geom_bs)\n",
    "    filename=output_file_text.value\n",
    "    end_of_epoch = to_date_picker.value\n",
    "    start_of_epoch=from_date_picker.value\n",
    "    \n",
    "    #Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "    bands_of_interest = ['blue',\n",
    "                         'green',\n",
    "                         'red',\n",
    "                         'nir',\n",
    "                         'swir1',\n",
    "                         'swir2'\n",
    "                         ]\n",
    "\n",
    "    query = {\n",
    "        'time': (start_of_epoch, end_of_epoch), 'geopolygon': geom\n",
    "    }\n",
    "     #Create a query to store spatiotemporal information from the previous landsat query\n",
    "    wofs_query = query\n",
    "    dcwofs = datacube.Datacube(config='/g/data/r78/dc_configs/wofscube.conf')\n",
    "    \n",
    "    wofs_data = dcwofs.load(product = 'wofs_albers', **wofs_query)\n",
    "\n",
    "    #Concatenate (join) the data from the different WOfS scenes together and sort so that observations are sorted \n",
    "    #by time\n",
    "    import matplotlib as mpl\n",
    "    wofs_cmap = mpl.colors.ListedColormap(['#C8B97D','#B3E5FC','#81D4FA','#4FC3F7','#29B6F6','#039BE5',\n",
    "                                       '#0288D1','#0277BD', '#01579B','#1A237E','#02033a','#5e0799'])\n",
    "    wofs_data.water.isel(time=5).plot(levels=[0, 127,128,300],cmap=wofs_cmap)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    shapes = fiona.open(shape_file)\n",
    "    #i is the index of the shape file we have chosen\n",
    "    i =0 \n",
    "    #copy attributes from shapefile and define shape_name\n",
    "    geom_crs = geometry.CRS(shapes.crs_wkt)\n",
    "    geo = shapes[i]['geometry']\n",
    "    geom = geometry.Geometry(geo, crs=geom_crs)\n",
    "    geom_bs = shapely.geometry.shape(shapes[i]['geometry'])\n",
    "    shape_name = shape_file.split('/')[-1].split('.')[0]+'_'+str(i)\n",
    "\n",
    "    filename=output_file_text.value\n",
    "    end_of_epoch = to_date_picker.value\n",
    "    start_of_epoch=from_date_picker.value\n",
    "    \n",
    "    #Define wavelengths/bands of interest, remove this kwarg to retrieve all bands\n",
    "    bands_of_interest = ['blue',\n",
    "                         'green',\n",
    "                         'red',\n",
    "                         'nir',\n",
    "                         'swir1',\n",
    "                         'swir2'\n",
    "                         ]\n",
    "\n",
    "    \n",
    "    query = {\n",
    "        'time': ('1900-01-01', '2017-12-01'), 'geopolygon': geom\n",
    "    }\n",
    "    rf=load_rainfall(query)\n",
    "\n",
    "\n",
    "\n",
    "    rf_average = rf.rainfall.mean(dim =('longitude','latitude'))\n",
    "    rf_mnthy_average = rf_average.resample('1M', dim='time',how='sum')\n",
    "    rf_mnthy_average\n",
    "\n",
    "    import matplotlib.dates as mdates\n",
    "    #plt.close('all')\n",
    "    years = mdates.YearLocator()   # every year\n",
    "    months = mdates.MonthLocator()  # every month\n",
    "    yearsFmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "    fig, ax5 = plt.subplots()\n",
    "    ax5.plot(rf_mnthy_average.time,rf_mnthy_average.values)\n",
    "\n",
    "    ax5.format_xdata = mdates.DateFormatter('%Y-%m')\n",
    "\n",
    "    ax5.set_title('Rainfall\\n')\n",
    "    #plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
